\chapter{Design of system}
\newpage

\section{Data Flow Diagrams}
\begin{figure}[h]
  \begin{center}
  \psfig{figure=./img/level1.eps,height=4.5in}
    \caption{DFD –level 0 for Docstash Application }
    \label{7}
\end{center}
\end{figure}

\vspace{0.2cm} User data files is backed up in multiple storage location. The integrity of user's data is checked and accordingly data consistency is maintained in the file storage while taking backup and metadata is updated by setting up redundant file server for recovery and these data is store in file storage.

\begin{figure}[h]
\begin{center}
  \psfig{figure=./img/level2.eps,width=6.5in,height=3.5in}
    \caption{DFD –level 1 for Docstash Application }
    \label{8}
\end{center}
\end{figure}

       \vspace{0.2cm}User's uploading data is handled by the server through scaling up and down and database is updated simultaneously. Further this uploaded data file is encrypted using AES-256 encryption algorithm and compressed. While streaming
           this data is decrypted in real time and displayed to the user.



\begin{figure}[h]
    \begin{center}
  \psfig{figure=./img/activity.eps,width=6in,height=4in}
    \caption{Activity Diagram for Docstash }
    \label{9}
\end{center}
\end{figure}

\vspace{0.2cm}Above figure explains the activity of user on Docstash. User uploads file and that file is divided into chunks and every chunk searched for duplicate copies. If duplicate copies are not found then that chunk is uploaded to the server and if chunk is already present in the database then that chunk is not uploaded again. While chunks are being uploaded, parallelly metadata is extracted from user file and metadata database is updated and creates hash for every file to check data integrity.          
